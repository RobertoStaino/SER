{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.environ['PYDEVD_DISABLE_FILE_VALIDATION'] = '1'\n",
    "\n",
    "import sys\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, learning_curve, validation_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier as kNN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "from utils.audio_preprocess import *\n",
    "from utils.septr import SeparableTr\n",
    "from utils.feature_exctraction_v2 import get3d_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Conv1D, Conv2D, MaxPooling1D,MaxPooling2D, Flatten, Dropout, BatchNormalization, Input\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "#import warnings\n",
    "#if not sys.warnoptions:\n",
    "#    warnings.simplefilter(\"ignore\")\n",
    "#warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ave maria üôèüèªüôèüèø\n",
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Crema = \"CREMA-D/AudioWAV/\"\n",
    "crema_directory_list = os.listdir(Crema)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "NSIZE = len(crema_directory_list)\n",
    "SAMPLE_SIZE = min(200000, NSIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry</td>\n",
       "      <td>CREMA-D/AudioWAV/1022_ITS_ANG_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angry</td>\n",
       "      <td>CREMA-D/AudioWAV/1037_ITS_ANG_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>CREMA-D/AudioWAV/1060_ITS_NEU_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>CREMA-D/AudioWAV/1075_ITS_NEU_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>CREMA-D/AudioWAV/1073_IOM_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotions                                  Path\n",
       "0    angry  CREMA-D/AudioWAV/1022_ITS_ANG_XX.wav\n",
       "1    angry  CREMA-D/AudioWAV/1037_ITS_ANG_XX.wav\n",
       "2  neutral  CREMA-D/AudioWAV/1060_ITS_NEU_XX.wav\n",
       "3  neutral  CREMA-D/AudioWAV/1075_ITS_NEU_XX.wav\n",
       "4  disgust  CREMA-D/AudioWAV/1073_IOM_DIS_XX.wav"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for file in crema_directory_list[:SAMPLE_SIZE]:\n",
    "\n",
    "    file_path.append(Crema + file)\n",
    "\n",
    "    part=file.split('_')\n",
    "    if part[2] == 'SAD':\n",
    "        file_emotion.append('sad')\n",
    "    elif part[2] == 'ANG':\n",
    "        file_emotion.append('angry')\n",
    "    elif part[2] == 'DIS':\n",
    "        file_emotion.append('disgust')\n",
    "    elif part[2] == 'FEA':\n",
    "        file_emotion.append('fear')\n",
    "    elif part[2] == 'HAP':\n",
    "        file_emotion.append('happy')\n",
    "    elif part[2] == 'NEU':\n",
    "        file_emotion.append('neutral')\n",
    "    else:\n",
    "        file_emotion.append('Unknown')\n",
    "        \n",
    "# dataframe \n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe Emotions/Path\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Crema_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "Crema_df['Emotions'] = pd.Categorical(Crema_df['Emotions'])\n",
    "Crema_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 72)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = np.array(Crema_df.Path[Crema_df.Emotions=='fear'])[1]\n",
    "data, sampling_rate = librosa.load(path)\n",
    "\n",
    "mel = librosa.feature.melspectrogram(y=data, sr=22050) \n",
    "mel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(Crema_df, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = get3d_data(train, test, feats = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling our data with sklearn's Standard scaler\n",
    "# scaler = StandardScaler()\n",
    "# x_train = scaler.fit_transform(x_train)\n",
    "# x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(nfilters1=128, nfilters2=64, nfilters3=32, size_kernel=5, nstrides=1, s_pool1=5, s_pool2=5, s_pool3=5):\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(filters=nfilters1, kernel_size=size_kernel, strides=nstrides, padding='same', activation='relu', input_shape=x_train.shape[1:]))\n",
    "    model.add(Dropout(0.2))    \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=s_pool1, strides = nstrides, padding = 'same'))\n",
    "\n",
    "    model.add(Conv2D(filters=nfilters2, kernel_size=size_kernel, strides=nstrides, padding='same', activation='relu'))\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(BatchNormalization())    \n",
    "    model.add(MaxPooling2D(pool_size=s_pool2, strides = nstrides, padding = 'same'))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(filters=nfilters3, kernel_size=size_kernel, strides=nstrides, padding='same', activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=s_pool3, strides = nstrides, padding = 'same'))\n",
    "\n",
    "    #model.add(Conv1D(filters=nfilters4, kernel_size=size_kernel, strides=nstrides, padding='same', activation='relu'))\n",
    "    #model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=16, activation='relu'))\n",
    "\n",
    "    model.add(Dense(units=6, activation='softmax'))\n",
    "    model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "\n",
    "    #rlrp = ReduceLROnPlateau(monitor='val_loss', factor=0.30, verbose=0, patience=2, min_lr=0.0000001)\n",
    "\n",
    "    #model.fit(x_train, y_train, batch_size=32, epochs=25, validation_data=(x_test, y_test), callbacks=[rlrp])    \n",
    "    \n",
    "    #model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(\n",
    "    model=cnn_model, \n",
    "    verbose=0, \n",
    "    batch_size=32, \n",
    "    loss=\"categorical_crossentropy\", \n",
    "    nfilters1 = 64, \n",
    "    nfilters2 = 64, \n",
    "    nfilters3 = 64, \n",
    "    nfilters4 = 64, \n",
    "    size_kernel = 3,\n",
    "    nstrides = 1,\n",
    "    size_pool = 5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'nfilters1': [256, 128, 64, 32],\n",
    "    'nfilters2': [256, 128, 64, 32],\n",
    "    'nfilters3': [256, 128, 64, 32],\n",
    "    'nfilters4': [256, 128, 64, 32],\n",
    "    'size_kernel': [3, 5],\n",
    "    'nstrides': [1, 2, 3],\n",
    "    's_pool1': [3, 5, 8],\n",
    "    's_pool2': [3, 5, 8],\n",
    "    's_pool3': [3, 5, 8]\n",
    "    #'optimizer': ['adam']\n",
    "}\n",
    "\n",
    "# Grid\n",
    "grid = RandomizedSearchCV(estimator=cnn_model, param_distributions=param_grid, cv=3, verbose=3, n_jobs=3, n_iter=1000) #GridSearchCV\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# Print\n",
    "print(\"Best hyperparameter: \", grid_result.best_params_)\n",
    "print(\"Best accuracy: \", grid_result.best_score_)\n",
    "\n",
    "best_model = grid_result.best_estimator_\n",
    "val_accuracy = best_model.score(x_test, y_test)\n",
    "print(\"Validaton accuracy: \", val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8683, 128, 299, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model().fit(x_train, y_train, validation_data=(x_test, y_test), epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SepTr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
